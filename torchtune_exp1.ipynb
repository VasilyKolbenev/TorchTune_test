{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtune in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (2.19.0)\n",
      "Requirement already satisfied: huggingface-hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (0.22.2)\n",
      "Requirement already satisfied: safetensors in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (0.4.3)\n",
      "Requirement already satisfied: sentencepiece in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (0.6.0)\n",
      "Requirement already satisfied: blobfile>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (2.1.1)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (4.66.2)\n",
      "Requirement already satisfied: omegaconf in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (2.3.0)\n",
      "Requirement already satisfied: torchao==0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtune) (0.1)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchao==0.1->torchtune) (2.2.1+cu121)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchao==0.1->torchtune) (1.26.2)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchao==0.1->torchtune) (23.2)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from blobfile>=2->torchtune) (3.20.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from blobfile>=2->torchtune) (2.2.1)\n",
      "Requirement already satisfied: lxml~=4.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from blobfile>=2->torchtune) (4.9.4)\n",
      "Requirement already satisfied: filelock~=3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from blobfile>=2->torchtune) (3.13.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets->torchtune) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (3.9.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets->torchtune) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub->torchtune) (4.11.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from omegaconf->torchtune) (4.9.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tiktoken->torchtune) (2024.4.16)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets->torchtune) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets->torchtune) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets->torchtune) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets->torchtune) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets->torchtune) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets->torchtune) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets->torchtune) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets->torchtune) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets->torchtune) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets->torchtune) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets->torchtune) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets->torchtune) (2024.1)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->torchao==0.1->torchtune) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchao==0.1->torchtune) (12.4.127)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->torchao==0.1->torchtune) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->torchao==0.1->torchtune) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:torchtune.utils.logging:Running LoRAFinetuneRecipeSingleDevice with resolved config:\n",
      "\n",
      "batch_size: 2\n",
      "checkpointer:\n",
      "  _component_: torchtune.utils.FullModelMetaCheckpointer\n",
      "  checkpoint_dir: /tmp/Meta-Llama-3-8B/original/\n",
      "  checkpoint_files:\n",
      "  - consolidated.00.pth\n",
      "  model_type: LLAMA3\n",
      "  output_dir: /tmp/Meta-Llama-3-8B/\n",
      "  recipe_checkpoint: null\n",
      "compile: false\n",
      "dataset:\n",
      "  _component_: torchtune.datasets.alpaca_cleaned_dataset\n",
      "  train_on_input: true\n",
      "device: cuda\n",
      "dtype: bf16\n",
      "enable_activation_checkpointing: true\n",
      "epochs: 1\n",
      "gradient_accumulation_steps: 16\n",
      "log_every_n_steps: 1\n",
      "loss:\n",
      "  _component_: torch.nn.CrossEntropyLoss\n",
      "lr_scheduler:\n",
      "  _component_: torchtune.modules.get_cosine_schedule_with_warmup\n",
      "  num_warmup_steps: 100\n",
      "max_steps_per_epoch: null\n",
      "metric_logger:\n",
      "  _component_: torchtune.utils.metric_logging.DiskLogger\n",
      "  log_dir: /tmp/qlora_finetune_output/\n",
      "model:\n",
      "  _component_: torchtune.models.llama3.qlora_llama3_8b\n",
      "  apply_lora_to_mlp: true\n",
      "  apply_lora_to_output: false\n",
      "  lora_alpha: 16\n",
      "  lora_attn_modules:\n",
      "  - q_proj\n",
      "  - v_proj\n",
      "  - k_proj\n",
      "  - output_proj\n",
      "  lora_rank: 8\n",
      "optimizer:\n",
      "  _component_: torch.optim.AdamW\n",
      "  lr: 0.0003\n",
      "  weight_decay: 0.01\n",
      "output_dir: /tmp/qlora_finetune_output/\n",
      "profiler:\n",
      "  _component_: torchtune.utils.profiler\n",
      "  enabled: false\n",
      "resume_from_checkpoint: false\n",
      "seed: null\n",
      "shuffle: true\n",
      "tokenizer:\n",
      "  _component_: torchtune.models.llama3.llama3_tokenizer\n",
      "  path: /tmp/Meta-Llama-3-8B/original/tokenizer.model\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/bin/tune\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/tune.py\", line 49, in main\n",
      "    parser.run(args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/tune.py\", line 43, in run\n",
      "    args.func(args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/run.py\", line 179, in _run_cmd\n",
      "    self._run_single_device(args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/run.py\", line 93, in _run_single_device\n",
      "    runpy.run_path(str(args.recipe), run_name=\"__main__\")\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 289, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/recipes/lora_finetune_single_device.py\", line 510, in <module>\n",
      "    sys.exit(recipe_main())\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/config/_parse.py\", line 50, in wrapper\n",
      "    sys.exit(recipe_main(conf))\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/recipes/lora_finetune_single_device.py\", line 503, in recipe_main\n",
      "    recipe = LoRAFinetuneRecipeSingleDevice(cfg=cfg)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/recipes/lora_finetune_single_device.py\", line 99, in __init__\n",
      "    self._dtype = utils.get_dtype(cfg.dtype, device=self._device)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/utils/precision.py\", line 122, in get_dtype\n",
      "    raise RuntimeError(\n",
      "RuntimeError: bf16 precision was requested but not available on this hardware. Please use fp32 precision instead.\n"
     ]
    }
   ],
   "source": [
    "!tune run lora_finetune_single_device --config llama3/8B_qlora_single_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune [-h] {download,ls,cp,run,validate} ...\n",
      "\n",
      "Welcome to the TorchTune CLI!\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "subcommands:\n",
      "  {download,ls,cp,run,validate}\n",
      "    download            Download a model from the Hugging Face Hub.\n",
      "    ls                  List all built-in recipes and configs\n",
      "    cp                  Copy a built-in recipe or config to a local path.\n",
      "    run                 Run a recipe. For distributed recipes, this supports\n",
      "                        all torchrun arguments.\n",
      "    validate            Validate a config and ensure that it is well-formed.\n"
     ]
    }
   ],
   "source": [
    "!tune --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:torchtune.utils.logging:Running LoRAFinetuneRecipeSingleDevice with resolved config:\n",
      "\n",
      "batch_size: 8\n",
      "checkpointer:\n",
      "  _component_: torchtune.utils.FullModelHFCheckpointer\n",
      "  adapter_checkpoint: null\n",
      "  checkpoint_dir: /tmp/Llama-2-7b-hf\n",
      "  checkpoint_files:\n",
      "  - pytorch_model-00001-of-00002.bin\n",
      "  - pytorch_model-00002-of-00002.bin\n",
      "  model_type: LLAMA2\n",
      "  output_dir: /tmp/Llama-2-7b-hf\n",
      "  recipe_checkpoint: null\n",
      "compile: false\n",
      "dataset:\n",
      "  _component_: torchtune.datasets.alpaca_cleaned_dataset\n",
      "  train_on_input: true\n",
      "device: cuda\n",
      "dtype: bf16\n",
      "enable_activation_checkpointing: true\n",
      "epochs: 1\n",
      "gradient_accumulation_steps: 64\n",
      "log_every_n_steps: null\n",
      "loss:\n",
      "  _component_: torch.nn.CrossEntropyLoss\n",
      "lr_scheduler:\n",
      "  _component_: torchtune.modules.get_cosine_schedule_with_warmup\n",
      "  num_warmup_steps: 100\n",
      "max_steps_per_epoch: 128\n",
      "metric_logger:\n",
      "  _component_: torchtune.utils.metric_logging.DiskLogger\n",
      "  log_dir: /tmp/lora_finetune_output\n",
      "model:\n",
      "  _component_: torchtune.models.llama2.lora_llama2_7b\n",
      "  apply_lora_to_mlp: false\n",
      "  apply_lora_to_output: false\n",
      "  lora_alpha: 16\n",
      "  lora_attn_modules:\n",
      "  - q_proj\n",
      "  - v_proj\n",
      "  lora_rank: 8\n",
      "optimizer:\n",
      "  _component_: torch.optim.AdamW\n",
      "  lr: 0.0003\n",
      "  weight_decay: 0.01\n",
      "output_dir: /tmp/lora_finetune_output\n",
      "profiler:\n",
      "  _component_: torchtune.utils.profiler\n",
      "  enabled: false\n",
      "  output_dir: /tmp/lora_finetune_output/torchtune_perf_tracing.json\n",
      "resume_from_checkpoint: false\n",
      "seed: null\n",
      "shuffle: true\n",
      "tokenizer:\n",
      "  _component_: torchtune.models.llama2.llama2_tokenizer\n",
      "  path: /tmp/Llama-2-7b-hf/tokenizer.model\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/bin/tune\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/tune.py\", line 49, in main\n",
      "    parser.run(args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/tune.py\", line 43, in run\n",
      "    args.func(args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/run.py\", line 179, in _run_cmd\n",
      "    self._run_single_device(args)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/_cli/run.py\", line 93, in _run_single_device\n",
      "    runpy.run_path(str(args.recipe), run_name=\"__main__\")\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 289, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/recipes/lora_finetune_single_device.py\", line 510, in <module>\n",
      "    sys.exit(recipe_main())\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/config/_parse.py\", line 50, in wrapper\n",
      "    sys.exit(recipe_main(conf))\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/recipes/lora_finetune_single_device.py\", line 503, in recipe_main\n",
      "    recipe = LoRAFinetuneRecipeSingleDevice(cfg=cfg)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/recipes/lora_finetune_single_device.py\", line 99, in __init__\n",
      "    self._dtype = utils.get_dtype(cfg.dtype, device=self._device)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchtune/utils/precision.py\", line 122, in get_dtype\n",
      "    raise RuntimeError(\n",
      "RuntimeError: bf16 precision was requested but not available on this hardware. Please use fp32 precision instead.\n"
     ]
    }
   ],
   "source": [
    "!tune run lora_finetune_single_device \\\n",
    "--config llama2/7B_lora_single_device \\\n",
    "batch_size=8 \\\n",
    "enable_activation_checkpointing=True \\\n",
    "max_steps_per_epoch=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/teamspace/studios/this_studio/torchtune_exp1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git add /teamspace/studios/this_studio/torchtune_exp1.ipynb\n",
    "git commit -m \"Добавлен ноутбук Jupyter\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git add /teamspace/studios/this_studio//torchtune_exp1.ipynb\n",
    "git commit -m \"Добавлен ноутбук Jupyter\"\n",
    "git push\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
